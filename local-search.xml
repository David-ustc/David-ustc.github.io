<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>双目立体视觉</title>
    <link href="/2021/02/26/stereo/"/>
    <url>/2021/02/26/stereo/</url>
    
    <content type="html"><![CDATA[<h2 id="双目立体视觉———《人工智能导论之computer-vision》实验报告"><a href="#双目立体视觉———《人工智能导论之computer-vision》实验报告" class="headerlink" title="双目立体视觉———《人工智能导论之computer vision》实验报告"></a>双目立体视觉———《人工智能导论之computer vision》实验报告</h2><h4 id="实验题目"><a href="#实验题目" class="headerlink" title="实验题目"></a>实验题目</h4><p>在middlebury数据集上实现双目立体视觉图像重建<br><img src="/img/stereo/exp_stereo.png" width = "380" style="align:center;" /></p><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><ol><li><strong>了解计算机视觉基本知识。</strong></li><li><strong>学习计算机数字图像处理基本概念。</strong></li><li><strong>双目视觉图像重建算法的学习与实践。</strong></li></ol><h4 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h4><ol><li><p><strong>双目立体视觉图像</strong><br>大体步骤有：双目标定 $\Rightarrow$ 立体校正（含消除畸变）$\Rightarrow$ 立体匹配 $\Rightarrow$ 视差计算 $\Rightarrow$ 深度/3D坐标计算<br>第三、四步包括：<br>(1)必须从一幅图像中选出位于场景中一个表面上的某一特定位置；<br>(2)必须在另一幅图像中鉴别出同一个位置；<br>(3)测出这两个对应像点之间的视差。在一组重复摄影的两张照片上(立体模式)，同一地物的影象，沿着摄影基线(摄影地点和下一个摄影地点之间的飞行方向线)方向位置变换，这个变化量叫<strong>立体视差</strong>。</p><br /></li><li><p><strong>双目标定</strong><br>双目标定的目标是获得左右两个相机的内参、外参和畸变系数，其中内参包括左右相机的fx，fy，cx，cy，外参包括左相机相对于右相机的旋转矩阵和平移向量，畸变系数包括径向畸变系数（k1， k2，k3）和切向畸变系数（p1，p2）。实验采用的<code>middlebury</code>数据集，包含校正效果已经很好的图像和参数表：<br><code>Here is a sample calib.txt file for one of the full-size training image pairs:</code><br><code>cam0=[3997.684 0 1176.728; 0 3997.684 1011.728; 0 0 1]</code><br><code>cam1=[3997.684 0 1307.839; 0 3997.684 1011.728; 0 0 1]</code><br><code>doffs=131.111</code><br><code>baseline=193.001</code><br><code>width=2964</code><br><code>height=1988</code><br><code>ndisp=280</code><br><code>isint=0</code><br><code>vmin=31</code><br><code>vmax=257</code><br><code>dyavg=0.918</code><br><code>dymax=1.516</code></p><br /></li><li><p> <strong>极线校正</strong><br>立体校正的目的是将拍摄于同一场景的左右两个视图进行数学上的投影变换，使得两个成像平面平行于基线，且同一个点在左右两幅图中位于同一行，简称共面行对准。只有达到共面行对准以后才可以应用三角原理计算距离。<br>如下图所示：</p><img src="/img/stereo/exp_align.png" width = "400" height="234"  style="align:center;" /><br /></li><li><p><strong>立体匹配与视差图计算</strong><br>假设两幅图像经过了校正，那么对应点的寻找限制在图像的同一行上。一旦找到对应点，由于深度是和偏移成正比的，那么深度（Z坐标）可以直接由水平偏移来计算，<br>其中，$f$是经过校正图像的焦距，$b$(baseline)是两个照相机中心之间的距离，$x_l,x_r$是左右两幅图像中对应点的横坐标，$x_l - x_r = disparity$为视差。<br>根据上图可以得到相似三角形：$\Delta_{p_l, p, p_r}  \sim  \Delta_{O_l, p, O_r}$<br>以及对应的性质：<br>$$\frac{b+ x_l - x_r}{b} = \frac{Z-f}{Z}$$<br>计算公式在校正后必要时加上修正，即$d = x_l - x_r +doffs=x_l-x_r+cx_0-cx_1$。</p><br /></li></ol><blockquote><p>双目视觉的重点在于匹配算法，接下来介绍几种基础的普通计算方法，并选取部分实践评估。常用的立体匹配方法基本上可以分为两类：局部方法例如<code>BM、SGM</code>等，非局部的，即全局方法例如<code>Dynamic Programming</code>、<code>Graph Cut</code>等。局部方法计算量小，匹配质量相对较低，全局方法省略了代价聚合而采用了优化能量函数的方法，匹配质量较高，但是计算量也比较大。目前<code>OpenCV</code>中已经实现的方法有<code>BM</code>、<code>binaryBM</code>、<code>SGBM</code>这几种方法。<br>此外在立体匹配生成视差图之后，还可以对视差图进行滤波后处理，例如<code>Guided Filter</code>、<code>Bilatera Filter</code>等。 视差图滤波能够将稀疏视差转变为稠密视差，并在一定程度上降低视差图噪声，改善视差图的视觉效果，但是比较依赖初始视差图的质量。<br><br /></p></blockquote><ol start="5"><li><p><strong>匹配像素算法———归一化互相关(NCC:Normalized cross-correlation)</strong><br>在立体重建算法中，我们将对于每个像素尝试不同的偏移，并按照局部图像周围归一化的互相关值，选择具有最佳评估结果的视差。因为每个偏移在某种程度上对应于一个平面，所以该过程有时称为扫平面法。<br>如有校正过的两帧图像，NCC算法对图像$I_1$一个待匹配像素构建$n*n$匹配窗口，在图像$I_2$极线上对每一个像素构建匹配窗口与待匹配像素匹配窗口计算相关性，相关性最高的视为最优匹配。由于NCC匹配流程是通过在同一行查找最优匹配，因此可以并行处理，对于运行效率有一定的提升。<br>我们使用每个像素周围的图像块（根本上说，是局部周边图像）来计算归一化的互相关。针对图像周围像素NCC公式：<br>$$ncc(I_1, I_2) =\frac{\sum_{x}(I_1(x) -\mu_1)(I_2(x)- \mu_2)}{\sqrt{\sum_{x}(I_1(x) -\mu_1)^2 \sum_{x}(I_2(x)- \mu_2)^2}}$$</p></li><li><p><strong>匹配像素算法————SGBM算法</strong><br>(1).预处理<br>SGBM采用水平<code>Sobel</code>算子，把图像做处理，公式为：<br>$Sobel ,(x,y)=2[P(x+1,y)-P(x-1,y)]+ P(x+1,y-1)-P(x-1,y-1)+ P(x+1,y+1)-P(x-1,y+1)$<br>用一个函数将经过水平<code>Sobel</code>算子处理后的图像上每个像素点（P表示其像素值）映射成一个新的图像：<code>P_new</code>表示新图像上的像素值，<code>prefiltercap</code>作为传递参数可定义。<br>$$P_{new} =<br>   \begin{cases}</p><pre><code>\qquad\qquad 0 \qquad\qquad p &lt;\text&#123;-prefiltercap&#125;;\\p+prefiltercap \qquad \text&#123;-prefiltercap&#125;\leq p \leq \text&#123;-prefiltercap&#125;;\\ 2*prefiltercap,\quad\quad p &gt;\text&#123;-prefiltercap&#125;.\end&#123;cases&#125;</code></pre><p>$$<br>预处理实际上是得到图像的梯度信息,经预处理的图像保存起来，将会用于计算代价。<br>(2).代价计算<br>大部分匹配算法中就是在校正图像上的每一行，寻找一条使得全局能量函数最小的最优匹配路径。在论文中，作者提出了一个具体的能量函数：$$L(D) = \sum_p [C(p,D_p) +\sum_{q\in N_p}p_1\cdot I(|D_p -D_q|=1)+\sum_{q\in N_p}p_2 I(|D_p -D_q|&gt;1)$$<br>opencv中两个参数P1，P2是这样设定的：<br><code>P1 =8*cn*sgbm.SADWindowSize*sgbm.SADWindowSize</code>;<br><code>P2 = 32*cn*sgbm.SADWindowSize*sgbm.SADWindowSize</code>。<br>Np 指像素p的相邻像素点；C(p, Dp)指当前像素点<code>disparity</code>为Dp时的<code>cost</code>函数值，<strong>可以为BT代价或者MI代价等</strong>，<code>SGBM</code>中能量函数一般定义为C(original)和C(smooth)之和，其中 C(data)为图像数据项用于判断匹配像素点之间的相似性，C(smooth)为<code>sobel</code>预处理之后像素点与邻域像素的平滑约束项，用于保证视差的连续性；<br>P1 是一个惩罚系数，它适用于像素p相邻像素中<code>disparity</code>值与p的<code>disparity</code>值相差1的那些像素；P2 是一个惩罚系数，它适用于像素p相邻像素中<code>disparity</code>值与p的<code>disparity</code>值相差大于1的那些像素；$I[]$示性函数如果函数中的参数为真返回1，否则返回0。<br>按照上述过程，只要依次求解每个阶段的最优值$min L_k()$，该行像素的视差也就求出来了。从这个过程中可以发现，该计算流程实际上就是接下来所要讲解的<code>SGM</code>在水平方向上的聚合。<br>(3).代价聚合和动态规划<br>动态规划即在水平扫描线的视差空间切面上寻找最优路径，如下图所示，以像素点的行方向为横坐标，视差值d 为纵坐标，依次将整个过程分为 1、2、3、…、k 共k个阶段。将上述各个阶段所处的匹配阶段用不同的状态表示。如下图所示，每一个阶段的状态就是对应像素点的匹配情况，共有三种状态：相互匹配记为 M、左可见右遮挡为 L、右可见左遮挡为 R，状态的选择满足无后效性。<img src="/img/stereo/exp_DP.png" width = "380" height="234"  style="align:center;" /><br>针对该思想，Hirschmuller提出了semi-global matching方法，通过在多个方向1维路径上平等地进行代价聚合，然后使用WTA求解视差，来作为一个近似求解2维能量最小化的过程。<strong>此时能量（损失）函数化简成：</strong><br>$$ L(r,d) = C(\bold{p},d) +min(L_r(\bold{p-r},d),L_r(\bold{p-r},d-1)+P_1,L_r(\bold{p-r},d+1)+P_1,min_iL_r(\bold{p-r},i)+P_2)-min_kL_r(\bold{p-r},k)$$<br>代价聚合的路径可以为8或16个，这样可以全面覆盖整张图像，最终的聚合代价是所有路径上聚合代价的和：$S(\bold{p},d) = \sum_r L_r(\bold{r},d)$<br>(4).视差计算<br>经过代价聚合后，根据<code>winner takes all</code>的思想，取最大值$d^* = argmin S(\bold{p},d)$得到视差图，即可进一步得到深度图。<br>(5).后处理<code>proprocessing</code>，这里只选取两步骤简要介绍。<br>A.唯一性检测<br>采用比率测试匹配筛选方法，即最低代价是次低代价的<code>(1+ uniquenessRatio/100)</code>倍的时候时，最低代价匹配的视差值才认为是正确视差值，否则这个像素点的视差值设定为负值。其中<code>uniquenessRatio</code>是一个常数参数，一般设置为0.8左右。<br>B.左右一致性检测<br> 设左图中像素p的视差为d，右图中对应像素的视差为d<em>，那么一般认为时，$|d-d^</em>|&lt;threshold$才最有可能为正确的视差，否则将其置为一个无效值。threshold一般取为1或者2。函数<code>cv2.stereoSGBM_create()</code>代码中已经介绍过该参数。</p></li></ol><h4 id="算法结构"><a href="#算法结构" class="headerlink" title="算法结构"></a>算法结构</h4><ol><li>ncc算法有两种处理方法，分别是采用平均滤波器和高斯滤波器计算归一化互相关系数ncc。两者除了<code>filter</code>不同，在算法上无差异，流程如下：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sql">def plane_sweep_ncc(im_l,im_r,<span class="hljs-keyword">start</span>,steps,wid):<br>    mean_l <span class="hljs-operator">=</span> <span class="hljs-keyword">filter</span>(im_l)<br>    mean_r <span class="hljs-operator">=</span> <span class="hljs-keyword">filter</span>(im_r)<br>    norm_l <span class="hljs-operator">=</span> im_l <span class="hljs-operator">-</span> mean_l<br>    norm_r <span class="hljs-operator">=</span> im_r <span class="hljs-operator">-</span> mean_r<br>    <span class="hljs-keyword">for</span> displ <span class="hljs-keyword">in</span> <span class="hljs-keyword">range</span>(steps):<br>        s <span class="hljs-operator">=</span> <span class="hljs-keyword">filter</span>(norm_l.roll(<span class="hljs-operator">-</span>displ <span class="hljs-operator">-</span> <span class="hljs-keyword">start</span>) <span class="hljs-operator">*</span> norm_r)  <br>        s_l <span class="hljs-operator">=</span> <span class="hljs-keyword">filter</span>(norm_l.roll(<span class="hljs-operator">-</span>displ <span class="hljs-operator">-</span> <span class="hljs-keyword">start</span>) <span class="hljs-operator">*</span> norm_l.roll(<span class="hljs-operator">-</span>displ <span class="hljs-operator">-</span> <span class="hljs-keyword">start</span>))<br>        s_r <span class="hljs-operator">=</span> <span class="hljs-keyword">filter</span>(norm_r <span class="hljs-operator">*</span> norm_r) <br>        dmaps[:, :, displ] <span class="hljs-operator">=</span> s <span class="hljs-operator">/</span> <span class="hljs-built_in">sqrt</span>((s_l <span class="hljs-operator">*</span> s_r)<span class="hljs-operator">+</span><span class="hljs-number">1e-5</span>)<br>    #选取最佳深度<br>    <span class="hljs-keyword">return</span> disparity <span class="hljs-operator">=</span> dmaps.argmax(, axis<span class="hljs-operator">=</span><span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure></li><li>Python语言程序包opencv（cv2）有与C++的接口，内部定义了SGBM对象，可直接操作。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import cv2<br>stereo = cv2.StereoSGBM_create(<br>    #最小视差，默认为0。此参数决定左图中的像素点在右图匹配搜索的起点。<br>    <span class="hljs-attribute">minDisparity</span>=0,<br>    <span class="hljs-attribute">numDisparities</span>=256,  # max_disp has <span class="hljs-keyword">to</span> be dividable by 16 f. E. HH 192, 256<br>    <span class="hljs-attribute">blockSize</span>=3,<br>    #控制视差变化平滑性的参数。P1越大，视差越平滑，P2越大，边缘越差。windowsize默认3; 5; 7 ; 本实验设置为3<br>    <span class="hljs-attribute">P1</span>=8 * 3 * window_size ** 2,<br>    <span class="hljs-attribute">P2</span>=32 * 3 * window_size ** 2,<br>    #一致性<br>    <span class="hljs-attribute">disp12MaxDiff</span>=1,<br>    #唯一性<br>    <span class="hljs-attribute">uniquenessRatio</span>=15,<br>    #视差连通区域像素点个数的大小。对于每一个视差点，当其连通区域的像素点个数小于size时，认为该视差值无效，是噪点。<br>    <span class="hljs-attribute">speckleWindowSize</span>=0,<br>    <span class="hljs-attribute">speckleRange</span>=2,<br>    #水平sobel预处理后，映射滤波器大小。默认为15<br>    <span class="hljs-attribute">preFilterCap</span>=63,<br>    <span class="hljs-attribute">mode</span>=cv2.STEREO_SGBM_MODE_SGBM_3WAY<br>)<br>    disparity = stereo.compute(img_left, img_right).astype(np.float32)<br></code></pre></td></tr></table></figure></li></ol><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><ol><li><p><code>middlebury</code>数据集提供了真实视差图图pfm文件，通过文件IO操作将字节序稍作变换，即可得到png图片。视差图作为数组读入后，运用一步公式和<code>calib.txt</code>标定文件参数，计算可得深度图。本小节全部以<code>Umbrella-perfect</code>为分析对象，视差图和深度图真值如下：</p><table><tbody><tr><td align="center"><div><img src="/img/stereo/disp0-gt.png" width="100%"></div></td><td align="center"><div><img src="/img/stereo/dep0-gt.png" width="100%"></div></td></tr></tbody></table></li><li><p><code>ncc</code>算法提出时期较早，效果不如新算法好，主要通过调节<code>wid</code>参数实现最佳匹配。<code>wid</code>越大，图像越平滑，但细节信息更少，<code>wid</code>越小，噪声越多，缺乏稳健性。下图分别是平均滤波器（wid=9）和高斯滤波器(wid=3)的视差图，可以明显看出物体轮廓不清晰。</p><table><tbody><tr><td align="center"><div><img src="/img/stereo/disp0-ncc.png" width="80%"></div></td><td align="center"><div><img src="/img/stereo/disp0-ncc2.png" width="80%"></div></td></tr></tbody></table></li><li><p>OpenCV的SGBM算法出彩之处在于后处理，受噪音、图像轮廓等因素影响小，从而成为主流的立体视觉匹配算法。实验成图和数据集真值图对比如下，虽然仍有差距，但是视觉上的匹配效果差强人意。</p></li></ol><table><tr><td align="center"><div><img src="/img/stereo/disp0-gt.png" width="100%" />&#x771F;&#x503C;&#x89C6;&#x5DEE;</div></td><td align="center"><div><img src="/img/stereo/disp0-sgbm.png" width="100%" />SGBM&#x89C6;&#x5DEE;</div></td></tr><tr><td align="center"><div><img src="/img/stereo/dep0-gt.png" width="100%"/>&#x771F;&#x503C;&#x6DF1;&#x5EA6;</div></td><td align="center"><div><img src="/img/stereo/dep0-sgbm.png" width="100%"/>SGBM&#x6DF1;&#x5EA6;</div></td></tr></table><blockquote><p>参考文献：<br>[1]vision.middlebury.edu/stereo/data/2014<br>[2]Hirschm. Stereo Processing by Semiglobal Matching and Mutual Information[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 30(2):328-341.<br>[3]blog.csdn.net/dulingwen/article/details/104142149<br>[4]blog.csdn.net/weixin_45617915/article/details/105763749</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>class report</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>eigenface方法</title>
    <link href="/2021/01/10/eigenface/"/>
    <url>/2021/01/10/eigenface/</url>
    
    <content type="html"><![CDATA[<h2 id="eigenface方法人脸识别———《模式识别导论》实验报告三"><a href="#eigenface方法人脸识别———《模式识别导论》实验报告三" class="headerlink" title="eigenface方法人脸识别———《模式识别导论》实验报告三"></a>eigenface方法人脸识别———《模式识别导论》实验报告三</h2><h4 id="实验题目"><a href="#实验题目" class="headerlink" title="实验题目"></a>实验题目</h4><ol><li>熟悉常⽤特征降维⽅法，了解并阐释PCA降维的基本原理；</li><li>熟悉<code>Eigenface</code>⼈脸识别的基本流程，利⽤<code>Eigenface</code>算法对训练集的样本进⾏训练，并进⾏⼈脸识别测试；</li><li>分析结果，并对本征脸⽅法的优缺点进⾏分析；</li><li>撰写实验报告。</li></ol><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><ol><li>学习降维原理，以及应用最广泛的PCA降维算法。</li><li>实现<code>eigenface</code>人脸识别，初步了解<code>computer vision</code>相关基础技术。</li><li>进一步熟悉<code>Python</code>科学计算，以及科学绘图。</li></ol><h4 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h4><ol><li><code>PCA</code>降维<br>目的是将一组N维向量$X_{N\times m}$降为K维（K大于0，小于N），选择K个单位正交基，使原始数据变换到这组基上后，各字段两两间协方差为0，字段的方差则尽可能大。<br>$ X =\begin{pmatrix}<br>a_1&amp;a_2&amp;a_3&amp;…&amp;a_m<br>\b_1&amp;b_2&amp;b_3&amp;…&amp;b_m<br>\end{pmatrix}$<br>矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。<br>$Cov = \frac{1}{m}XX^T = \begin{pmatrix}<br>\frac{1}{m}\sum_{i=1}^{m}a_i^2 &amp;\frac{1}{m}\sum_{i=1}^{m}a_i b_i<br>\\frac{1}{m}\sum_{i=1}^{m}a_i b_i&amp;\frac{1}{m}\sum_{i=1}^{m}b_i^2<br>\end{pmatrix}$<br>求出$Cov$的特征值和特征向量矩阵$P$，并且实对称矩阵$Cov$可以相似对角化，乘以矩阵的n个单位正交特征向量即可。<br>$PCovP^T = \Lambda = \begin{pmatrix}<br>\lambda_1&amp;&amp;&amp;&amp;<br>\ &amp;\lambda_2&amp;&amp;&amp;<br>\ &amp;&amp;\lambda_3&amp;&amp;<br>\ &amp;&amp;&amp;…<br>\ &amp;&amp;&amp;&amp;\lambda_n<br>\end{pmatrix}$<br>特征值从大到小排列，取前k行对应的单位正交特征向量组成的矩阵$E = \begin{pmatrix}<br>e_1&amp;e_2&amp;e_3&amp;…&amp;e_k<br>\end{pmatrix}$乘以原数据矩阵$X$，就得到了需要的降维之后的矩阵$Y = EX$。</li></ol><p>2.<code>eigenface</code>人脸识别算法<br>人脸图像images $ I_{W\times H  }$，设数量为P。<br>将图像作<em>Flatten</em>操作，变成一维向量$ I=\begin{pmatrix}<br>a_1<br>\a_2<br>\…<br>\a_{N^2}<br>\end{pmatrix}<br>   <em>{（W\times H = N^2）}$<br>所有的人脸图像组成矩阵$ X</em>{N^2 \times M} = \begin{pmatrix}<br>I_1&amp;I_2&amp;I_3&amp;…&amp;I_M<br>\end{pmatrix}$</p><p>计算平均脸$avg =\frac{1}{P} \sum_{i=1}^{P} I_i = \frac{1}{P}<br>\begin{pmatrix}<br>a_1 + b_1 + … h_1<br>\a_1 + b_1 + … h_1<br>\…<br>\a_{N^2} + b_{N^2} + … h_1<br>\end{pmatrix}$</p><p>计算类协方差矩阵$Cov’ = X^TX$，这是由于原协方差矩阵计算量过大，改为求$Cov’$的特征向量矩阵，与原想要求解的仍然一致。<br>求出特征向量矩阵$eigVects$，默认取所有的特征向量也就是<code>select_rate = 1</code>，这是因为学习集样本不多。<br>接下来伪代码如下：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-attr">Cov</span> = XX^T<br><span class="hljs-attr">CovVects</span> = <span class="hljs-attr">FaceVects</span> = X*eigVecs<br>for i from <span class="hljs-number">0</span> to P:<br>    <span class="hljs-attr">TrainVects</span> = FaceVects.T * X[i]<br>    <span class="hljs-attr">theta</span> = MAX&#123; ||TrainVects - TrainVects_j||**<span class="hljs-number">2</span>       <span class="hljs-attr">j=0,1...P</span> &#125;<br>    <span class="hljs-attr">weiVec</span> = FaceVects.T * judgeFace<br><br><span class="hljs-attr">reconstruct</span> = FaceVector *weiVec<br><span class="hljs-attr">epsilon</span> = MIN&#123; ||weiVec - TrainVects||**<span class="hljs-number">2</span> &#125;<br></code></pre></td></tr></table></figure><p>$\xi$ = ||TrainVects - reconstruct||^2<br>$\xi &gt; theta $ 说明恢复后的图像与学习到的人脸库差别太大，故不属于人脸；<br>$\xi &lt; theta $ and $\varepsilon_{min} \geq theta $ 说明和任意一张学习到的特征脸都相差较大，是未识别过的人脸；<br>$\xi &lt; theta $ and $\varepsilon_{min} \leq theta $ 则测试图像属于$\varepsilon_{min}$对应的特征脸。</p><h4 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h4><ol><li>函数<code>loadImageSet</code>将人脸整合为数据矩阵。</li><li><code>RecognitionVector</code>处理人脸，提取特征脸。<br>算法如下：<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-symbol">alorithm2:</span> ReconginitionVector<br><span class="hljs-symbol">input:</span> select_rate=<span class="hljs-number">1</span><br><span class="hljs-symbol">output:</span> avgImg,covVects,<span class="hljs-keyword">diffTrain</span><br><span class="hljs-keyword"> </span>   FaceMat = loadImageSet(<span class="hljs-string">&#x27;./Dataset/trainingset/&#x27;</span>)<br>    avgImg = mean_along_axis0(FaceMat)<br><br>    <span class="hljs-keyword">diffTrain </span>= FaceMat-avgImg<br>    covMat =<span class="hljs-keyword">diffTrain </span>*<span class="hljs-keyword">diffTrain^T</span><br><span class="hljs-keyword"> </span>   <span class="hljs-keyword">eigvals </span>= <span class="hljs-keyword">eigenvaluesof(covMat) </span><br>    <span class="hljs-keyword">eigVects </span>= <span class="hljs-keyword">eigenvectorsof(covMat)</span><br><span class="hljs-keyword"> </span>   <br>    <span class="hljs-keyword">eigvals </span>=sort(-<span class="hljs-keyword">eigvals) </span><span class="hljs-comment">#按特征值从大到小，取前k个</span><br>    MIN &#123;i s.t. sum(<span class="hljs-keyword">eigvals[0:i])/sum(eigvals[]) </span>&gt;= selectrate&#125;<br><br>    covVects = <span class="hljs-keyword">diffTrain.T </span>* <span class="hljs-keyword">eigVects[][0:i] </span><br></code></pre></td></tr></table></figure></li><li><code>JudgeFace</code>测试来自同一批采集者但是不同的表情和环境的人脸图像<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-symbol">algorithm3:</span> <span class="hljs-keyword">judgeFace</span><br><span class="hljs-keyword">input: </span><span class="hljs-keyword">judgeImg,FaceVector,avgImg,diffTrain</span><br><span class="hljs-keyword">output: </span>the <span class="hljs-keyword">eigenface </span>the testing face <span class="hljs-keyword">belongs </span>to <span class="hljs-keyword">or </span>alert <span class="hljs-string">&quot;a new face&quot;</span><br>    <br>    <span class="hljs-keyword">diff </span>= <span class="hljs-keyword">judgeImg </span>- avgImg<br>    weiVec = FaceVector.T* <span class="hljs-keyword">diff</span><br><span class="hljs-keyword"> </span>   reconstruct = FaceVector *weiVec<br>    <span class="hljs-comment">#====================================================================</span><br>    <span class="hljs-comment">#plt.imshow(reconstruct.reshape(195,231))</span><br>    <span class="hljs-comment">#plt.show()</span><br>    <span class="hljs-comment">#====================================================================</span><br>    epsilonmin = np.inf<br>    imin = <span class="hljs-number">0</span><br>    for i from <span class="hljs-number">0</span> to FaceVector.<span class="hljs-keyword">shape[1]:</span><br><span class="hljs-keyword"> </span>       TrainVec = (<span class="hljs-keyword">diffTrain[i]*FaceVector).T </span>       <span class="hljs-comment">#omega_i</span><br>        TrainVects_j = (<span class="hljs-keyword">diffTrain[j]*FaceVector).T </span>   <span class="hljs-comment">#omega_j</span><br>        thetamax = MAX&#123;<span class="hljs-keyword">j: </span><span class="hljs-title">||</span>TrainVects - TrainVects_j<span class="hljs-title">||</span>^<span class="hljs-number">2</span> &#125;<br><br>        epsilon = <span class="hljs-title">||</span>weiVec-TrainVec<span class="hljs-title">||</span>^<span class="hljs-number">2</span>               <span class="hljs-comment">#omega - omega_i </span><br>        if epsilon &lt; epsilonmin:  <br>            epsilonmin = epsilon <span class="hljs-keyword">and </span>imin=i<br><br>    if epsilonmin &gt;= thetamax:<br>        alert(the face to <span class="hljs-keyword">be </span><span class="hljs-keyword">judged </span>is a new face)<br>    elif epsilonmin &lt; thetamax:<br>        print(the face <span class="hljs-keyword">belongs </span>to the same person as <span class="hljs-string">&#x27;imin&#x27;</span>)<br></code></pre></td></tr></table></figure></li></ol><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><ol><li><p>训练集提取特征<br>训练集由135张人脸组成，分别来自15个人，有<code>glasses</code>，<code>leftlight</code>，<code>happy</code>，<code>sad</code>等多种环境。<br>程序中选取前k个特征值，使得其和大于<code>selec_trate=0.8</code>的总特征值之和，提取出16张特征脸数据。</p></li><li><p>测试集进行评估<br>100%识别出属于训练集的人脸；<br>但是正确率只有90%，其中01和02测试样本来自同一个人，测试结果认为是来自不同的样本，01和02样本错认成了学习的两张特征脸7和6。</p><img src="/img/eigenface/test.png" width = "300"  align="center" /><br />此外，实验测试集中，加入了一张非学习样本的人脸图像，文件名`subject11.happy.png`，大小尺寸一样，同为灰度图，如下所示。但是可以从上图运行界面看出，测试结果“过拟合”识别成某一张学习的样本人脸。<img src="/img/eigenface/subject11.happy.png" width = "150"  align="center" /><br /></li><li><p><code>eigenface</code>优缺点分析<br>(1)<code>eigenface</code>实际应用的一个问题，就是在不同的光照条件和成像角度时，会导致识别率大幅下降。因此，使用特征脸需限制在统一的光照条件下使用正面图像进行识别。<br>(2)算法可以挖掘出数据集的线性特性，但是遇到非线性结构时，往往不能达到理想的识别效果。<br>(3)泛化能力不强，尤其是在学习集不大的时候，迁移到未学习过的测试集上会误当作学习到的特征，准确率不高。</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>class report</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>感知机算法</title>
    <link href="/2020/10/20/MLP/"/>
    <url>/2020/10/20/MLP/</url>
    
    <content type="html"><![CDATA[<h2 id="感知机算法求线性分界面———《模式识别导论》实验报告一"><a href="#感知机算法求线性分界面———《模式识别导论》实验报告一" class="headerlink" title="感知机算法求线性分界面———《模式识别导论》实验报告一"></a>感知机算法求线性分界面———《模式识别导论》实验报告一</h2><h4 id="实验题目"><a href="#实验题目" class="headerlink" title="实验题目"></a>实验题目</h4><ol><li>已知二维模式样本集$X_1={(1,0),(1,1),(0,2)}$,$X_2={(2,1),(2,2),(1,3)}$,用感知机算法固定增量求分界面方程，并且作图；</li><li>分别改变初始权向量和样本集中的顺序来获得不同结果；  </li><li>（选做）自定义线性不可分样本，通过限定算法迭代次数得到结果并分析。</li></ol><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><ol><li>学习线性可分问题以及感知机算法</li><li>熟悉<strong>numpy</strong>等包工具，掌握科学绘图</li><li>线性不可分问题的分析与处理</li></ol><h4 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h4><p>对于两类（$\omega_i, \omega_j$）线性分类问题，给定一个D维样本$\chi = [\boldsymbol x_1,\boldsymbol x_2,…\boldsymbol x_n]^T$，我们用<br>$$\hat y = sgn(\boldsymbol w^T \boldsymbol x_k)\qquad  k=1,2,…n$$<br>上式已转化为增广形式，即$\boldsymbol x = [x_1,x_2,…x_D,1]^T，\hat y = sgn(g(\boldsymbol x))$</p><p>$$ g(\boldsymbol{x, w}) = w_1x_1+w_2x_2+…+w_Dx_D+b = \boldsymbol w^T \boldsymbol x$$</p><p>对于(g&gt;0 ，\hat y=1)，认为(x \in \omega_i);(g&lt;0 ， \hat y= -1)，认为(x \in \omega_j)。同理，我们用这种规则来标注样本，作为标签值$y^{(k)}$。<br>作为判别函数，几何上$ w $可表示为一个多维空间中的（超）平面的法向量，这个平面称为分界面。<br>如何得到一个好的$ g(\boldsymbol x) = w^T \boldsymbol x$，实验采用感知机算法，描述如下：</p><ol><li>迭代数<code>epochs</code>=0, 赋$w$初值。</li><li>输入$\boldsymbol x_k$。</li><li>计算函数值$g(\boldsymbol x_k)$。</li><li>修正权向量$w_k$，<code>epochs</code>表示迭代代数。<br>运用以下算法，计算$\boldsymbol w_k^Tx^{(k)}$和$y^{(k)}$是否异号来进行迭代决策，无需改变样本集$\omega_j$中的$\hat y$。<br /><br>if $\boldsymbol w_k^T(y^{(k)}\boldsymbol x^{(k)})\leq0$ then<br>$\boldsymbol w = \boldsymbol w + c*y^{(k)}\boldsymbol x^{(k)}$<br>其中$c$为学习率，取0,1之间的值。</li><li><code>epochs</code>+1，进入下一轮迭代。直到w对所有训练样本均稳定不变，程序结束。</li></ol><h4 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h4><ol><li>本实验通过<strong>numpy</strong>科学包处理。<br>超参数取$c = 1$。$w$已经采用增广形式，并且在numpy的矩阵表示中，一维向量认为是行向量。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">features = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>]])<br>labels = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>]).reshape(<span class="hljs-number">6</span>,<span class="hljs-number">1</span>)<br>w = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]) <br></code></pre></td></tr></table></figure><ol start="2"><li>利用<strong>pandas</strong>包对矩阵进行行重排，随机排列$\chi$内样本点，以得到不同的样本集及结果。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">featuresT = features.transpose()<br>print(featuresT)<br>print(np.array(pd.DataFrame(featuresT).reindex(columns=[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>]))) <span class="hljs-comment">#需手动指定重排顺序</span><br>features = featuresT.transpose()<br></code></pre></td></tr></table></figure><ol start="3"><li>开始训练，采用如上所述修正$w$算法。<br>检测$w$何时对所有样本收敛，停止迭代。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在一轮循环前</span><br>v = np.array(w)<br><span class="hljs-comment"># 开始一轮</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_examples)：<br>        ……<br>u = (v == w)<br><span class="hljs-keyword">if</span>(u.<span class="hljs-built_in">all</span>() == <span class="hljs-literal">True</span>):<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><ol><li><p>调整样本点顺序，对最终结果无影响，但是改变$w$初始向量值会导致结果不同。<br>初始$\boldsymbol w=(1,1,1)$ $\boldsymbol w_1 = (-4,-2,8)$<br>初始$\boldsymbol w=(1,2,1)$ $\boldsymbol w_2 = (-4,-2,8)$<br>初始$\boldsymbol w=(-5,-4,1)$ $\boldsymbol w_3 = (-3,-1,5)$<br>初始$\boldsymbol w=(0,2,1)$ $\boldsymbol w_4 = (-3,-1,5)$<br>初始$\boldsymbol w=(-10,-10,1)$ $\boldsymbol w_1 = (-4,-2,9)$  </p></li><li><p>画图调用<strong>matplotlib</strong>包<br>$\boldsymbol w = (1,1,1)$，<code>epochs</code>=15轮后权向量收敛，<br>分界面$w_0 x + w_1 y + w_2 z = 0$，由于$z = 1$<br>分界面在平面上的投影为$y = - w_0x /w_1 - w_2/w_1$<br>结果如下所示：蓝色点代表样本集，绿色直线即为投影。<br><img src="/img/mlp/figure_1.png" alt="figure_1" title="plot w=[1,1,1]"></p></li></ol><h4 id="选做实验"><a href="#选做实验" class="headerlink" title="选做实验"></a>选做实验</h4><p>1.<strong>不可分样本问题</strong><br>自定义线性不可分样本$\chi _1={(1,0),(0,2)}$,$X_2={(0,0),(3,1)}$,用感知机算法求分界面方程。</p><p>2.<strong>处理方法</strong><br>设置<code>max_epochs = 500</code>，一轮循环过后，如果达到最大迭代数，结束程序。</p><p>3.<strong>计算结果</strong><br>初始$\boldsymbol w=(1,1,1) \qquad \boldsymbol epochs =501\qquad w_1 = (-3,1,-2)$<br>初始$\boldsymbol w=(4,-2,1) \qquad \boldsymbol epochs =501\qquad w_1 = (-1,2,-1)$<br>可以得出结论，线性不可分样本，算法不能收敛到某一个分界面，如果不设置轮数限制，会无止境的计算下去。为此，通常情况应该设置一个足够大的<code>max_epochs</code>，以防止陷入死循环。</p>]]></content>
    
    
    
    <tags>
      
      <tag>class report</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《失控》读后感</title>
    <link href="/2020/08/16/out%20of%20control/"/>
    <url>/2020/08/16/out%20of%20control/</url>
    
    <content type="html"><![CDATA[<h1 id="洞悉明天的智慧和勇气"><a href="#洞悉明天的智慧和勇气" class="headerlink" title="洞悉明天的智慧和勇气"></a>洞悉明天的智慧和勇气</h1><p>——《失控》读后感/《技术、财富与文明变迁》 结课报告</p><blockquote><p>“所有的东西，都变成了另外的东西，所有的东西都是一种流动的状态，都在不断地改变。”                                          ——凯文·凯利 </p></blockquote><p>《失控》是一本被互联网行业奉为预言经典的书，在上个世纪末就以极其敏锐的视角，对未来尝试一窥究竟。从社会生物化到产业网络化；从分布并行的盛行到失去控制的定局；从信息爆炸逼迫共同进化，到开放进化催生自我调节，凯文·凯利（下称KK）充满智慧的洞见让二十一世纪的读者也叹为失色。<br>这是一本读起来“不轻松”的书。我初读起来很缓慢，后来跟着作者的逻辑飞速运转，才能勉强读完。KK渴望采用大量实例，引入丰富知识以保证论证的专业性。<br>全书主要讲述生物社会逻辑、控制管理逻辑、产业网络逻辑以及最后章节的进化逻辑。各个章节看似自说自话，实则串珠连线。作者看到了一系列并行、分布、嵌套、共赢的趋势，千万思绪汇成一句箴言“人类必然迎来失控”i。这既非危言耸听，也非无稽之谈。他给全人类以提醒，同时又提出“协同控制、伙伴关系”的可能性。进化是必然的，我们便要在万变的过程中通过进化革新，赢得不变的生存资格，适应纷繁多变的世界。这是最后KK想要告诉我们的方法论。</p><p>本书最亮眼的观点，放在了开头，“机器，正在生物化；而生物，正在工程化。”i这在今天看来完全属实。人工智能这个热门词，正如课堂上所讲，早已被搬上历史舞台，每一次新的研究突破都意味着又一轮浪潮，融资，投资，倾覆之后再融资……一轮轮泡沫的扫除之后，如今人工智能发展稳定，再有了深度学习的技术实现、类脑模型的日趋完善，大规模应用已经融入动漫、家居、教育等许多行业。<br>智能是否将取代人工？这样的恐惧早已渗透进每个产业的角落。<br>在KK看来，他提出的控制论未来格局——“人机协同控制”，不会迅速被推翻。只不过我们要警惕“失控”的局面，谨慎对待我们的技术和发明。所以人和智能发明将和谐相处，而不是一山不容二虎的关系。<br>医学是一个很典型的例子。国际影像战略策略研讨会主席Donoso指出，人工智能是否会完全替代影像科医生这一问题无法下定论，并且很有可能不会，但是我们可以确定的是，那些使用人工智能技术的医生势必会代替那些不用技术的医生。  医工交叉融合，“智慧+诊疗”不会让人类丢掉饭碗，但是能够更好的服务于医学本身，在这其中人为作用依然重要。形形色色的其它行业也一样。<br>抛开职业应用层面，我认为，人类凭借着机器无法拥有的人性和思想，不可能完全被智能取代，也不可能任由自己的创造品不受控制、逍遥法外。在一部历史迷你剧《切尔诺贝利》中，有这样一段情节：爆炸的核电站内有巨量辐射，当时最先进的电子芯片和机器在该环境下直接瘫痪。此时反应堆的清扫和封锁只能由人类来完成。据真实记载，当时的敢死队自愿报名却人数过量。队员们有为国家献身的勇气，有打破极限的毅力，即使再痛苦的条件也甘愿咬牙牺牲。机器不会迎来文艺复兴的精神大革命，不能胜任美学、社会学等等独特的创造性工作，单是凭这一点就可以认为人比机器多那么一份热血和情谊，这是人机不可逾越的鸿沟。如果真有人机对立的那一刻，我相信心理战的胜利属于人类。<br>紧接着产生的问题是智能的个性化与安全性。KK在段落里感慨，“咬人的房间会伤害入侵者，不咬人的房间会把客人带到安全的地方。”i我们在借用他人的设备时，通常感觉到陌生是因为个性化设置在作祟；非智能的设备在新用户和老玩家面前是相同的运行机制，以至于常常被迷糊的人折腾或是被恶意病毒攻击。KK认为，机器“社会”必有个性，但也会出现大统一的趋势——机器应该学会和其他同类相处交流，必须在分享中共存。这般富有想象力的想法，完全可以为科技公司提供市场方向的启发。</p><p>通往“失控”和“设备生物化”的途径必定是无处不在的进化。不论是政治民主，自然生物，代码程序还是以假乱真的VR游戏，进化都在它们内部运转着，宛如火车永不停息的燃油机，激发“自生成、自支持、自转化”的特质，创造无序之有序。<br>书的后半部分里，KK围绕进化的主题引入了许多的专业术语，而且每一个都用得恰到好处。从马尔可夫性我们能领悟社会发展的无记忆，从递归循环我们能看到诡异的轮回相似性，从文化基因（meme）我们观察到人类文明在进化的脚步中升级换代。<br>如何发现进化的内在规律？如何挖掘大自然无中生有的创造奥秘？凯文凯利尝试从“计算机科学和生物研究的最前沿成果中以及交叉学科的各种犄角旮旯里”i寻找答案，集大成于最后一章，总结出一系列普适的规律。我摘取浓缩了发人深省的几点。 </p><p>（一）试探性突破，模块化升级，爆发式增长，是KK认为进化未来的特点。<br>一旦感知对了信息社会的发展方向，不论是谁，顺着大势所趋便能很快成为业内领先的“明日之星”。只不过我们还得在市场里小心谨慎，因为风口上飞起来的不一定是价值暴涨的猪，也有可能只是一堆轻飘飘的棉花。<br>从命令行界面开始的操作系统受益于windows的图形化，而后则是客户/服务器结构简化、多任务交互功能等一步步模式理念的创新带动了真正的市场化；数据库管理系统不再由人工管控，技术人员们尝试推出新的关系数据库主导的理念，应对多用户多应用共享的需求，开启了数据库的腾飞时代；  共享经济是经历过大风大浪的新成员，各大城市疯狂投放设备的场景历历在目，如今共享单车有美团、摩拜、哈罗三足鼎立，巨头们也还在试着转型，为使用者打通最后一公里。这些都是近几十年技术和经济上的飞跃过程所体现出的特征。</p><p>（二）共生、定向变异、自适应是进化个体具备的特点。<br>在重要的信息交换中，不同的进化汇聚到一起呈现“趋同”之大势；非随机的变异仍然层出不穷，似乎是朝着某一个必然结果；同时个体在进化中不断地获得反馈，完成一个提升自我纠错能力的成长过程。这些都是KK通过援引众多自然界和互联网实例，想要看透的进化个体的本质。</p><p>（三）互联网是进化进程中关键的一环。<br>KK在书中传递了他对互联网的本质理解：它是一个失控的生物体，世界将因此去中心化。在他的预想里，万物互联将不是虚幻，是非线性网络连接带给社会层级的冲击和重构，并且将变成触手可及的现实。在互联网给我们带来的无限思考空间之中，KK指出“我们会为我们创造出意外惊喜。”<br>诚然，人人都在网上的事实，扭转了现实社会的发展趋势，也埋藏着人际关系、隐私安全、技术边缘人群等一系列问题。我们本次课程详细地就此讨论过。KK在第二十三章既没有避而不谈，但也没有多涉及。和KK一样，我们坚信互联网新事物的隐患需要解决；但互联网创新性更多的意味着生活便捷和福祉，需要被挖掘出来，需要开发和应用。</p><p>此外，我还受到了一些启发，补充在第四点：<br>（四）来自“天敌”的驱动力也是进化不可或缺的因素，最适合的例证便是鲶鱼效应。能够搅动浑水的强有力的对手，始终是一个行业进化的动力。就像非洲大草原上，鹿的生存本领是为了躲避美洲狮的追捕一天天变强的。<br>新能源汽车中，特斯拉是全球的榜样，自2019年引进国内以来，它也是一条所向披靡的“鲶鱼”乃至“鲨鱼”。近年来我国车企烧钱不断，技术乏新，续航一拧，全是水分，  与特斯拉这个领跑者还差很远。2020年开局,特斯拉在中国市场的战略便交出了满意的答卷，逆风而行扶摇直上，让国内的蔚来、理想、威马等新能源车企坐不住了。他们不得不开始寻找产品突破，谋求市场份额，从而有了更多的技术升级动力。国内的车企骄子能不能赢得竞争的胜利？我们期待它们以后在生存战的表现。  </p><p>虽然此书希望对未来予以一眼展望，凯文·凯利却认为人类不应该过于长远考虑，思前顾后只会束缚自我。尤瓦尔·赫拉利的一句话与此不谋而合，“人工智能等技术毫无疑问会改变我们的世界，但是我们未来的社会究竟怎样，有很多选择不是完全由技术决定的，一切都悬而未决。”  KK不愿意成为一个自诩为预言家的人，但他用这本书告诉世人，人类应该少一分被动选择的愚昧，多一分对当下的主动的、审慎的思考。  </p><p>信息革命始于千年之前，走过了微机新时代、互联网元年，即将迎来摩尔定律的尽头、虚拟现实的潮流，至今仍生生不息。这是第一节课张老师就告诉我们的。包括控制论、大数据、物联网在内的工业革命4.0悄然而至，刷新未来的一切可能性。此时人类不该害怕，也不会迷茫。我们一边持有拥抱明天的志气和勇气，一边走好脚下的路。人类社会不会是一帆风顺的，世界进化升级的过程还靠全人类一起打拼。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[^1]（美）凯文·凯利. 失控：全人类的最终命运和结局 [M]. 北京，电子工业出版社，2016.<br>[^2] 张栋. 中科院田捷教授：基于AI和医疗大数据的影像组学研究及其临床应用 [EB/OL]. [2018-07-04]. <a href="https://www.leiphone.com/news/201807/08Nk9vPGWUCDsvc3.html">https://www.leiphone.com/news/201807/08Nk9vPGWUCDsvc3.html</a>.<br>[3^] 王珊, 陈红. 数据库系统原理教程 [M]. 北京，清华大学出版社，2020.<br>[4^] 吴晓波. 27万的特斯拉：当鲶鱼变成鲨鱼 [EB/OL]. [2020-05-23]. <a href="https://mp.weixin.qq.com/s/SxiD_i2tnDH-2paN7MVUrQ">https://mp.weixin.qq.com/s/SxiD_i2tnDH-2paN7MVUrQ</a>.<br>[5^]（以色列）尤瓦尔·赫拉利. 人类简史：从动物到上帝 [M] 北京，中信出版集团，2017.</p>]]></content>
    
    
    
    <tags>
      
      <tag>class report</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最后一程</title>
    <link href="/2020/08/10/%E6%9C%80%E5%90%8E%E4%B8%80%E7%A8%8B/"/>
    <url>/2020/08/10/%E6%9C%80%E5%90%8E%E4%B8%80%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>“马孔多在下雨。”<br>奶奶过世的第二天，人们还是感到事情来得突然。忙，依旧是忙，男人们扛着大批大批重物进进出出，女人们帮着沏茶和后厨之类杂事。我站在窗前，早已习惯了沉默和凝视。门前的湖装着新的养殖喷水机器，水喷涌而出洒在水面上，泛开一圈又一圈波浪，仿佛哭起来就停不住的小姑娘。雨渐渐减弱，一滴滴雨点打在波纹上，有小小的泡泡圈，却没有改变那个更大的喷泉波阵。云还是黑压压的，逗留在半山腰上，雨不会永远走开，小雨只是一时的歇息，正如人们一阵一阵的却又无法愈合的忧伤。<br>许多粗活是单调的，我盯着一位老人砍竹竿，他不过是拿起锯子移动柱子反反复复切割，收拾了一箩筐竹片。人们都是在做着重复的工作，泡茶、洗菜、擦拭，在循环往复中麻木心灵。相哥哥和我坐一条长板凳，说他很理解祖辈们为什么规定丧事有这么多流程规矩了，就是先让晚辈们在张罗繁重的事情中暂停思绪，止住悲伤，好不用想不开做出什么疯狂举动。这也是晚辈能为在老人生前的不孝所做最后的赎罪了。“以后回想起来，总有一点回忆能够揭开人的伤疤，激起止不住的悲痛。那时可能人哭的比现在还厉害。”相哥哥从嘴里抽出烟，叹息着说。奶奶的去世仿佛让他一夜里老成了许多，不再是那个不谙世事的浪子青年。<br>吃过饭现在是午后，男人们就近七零八落的倒在垫子上打盹，以弥补彻夜的难眠，缓解白天的劳累。哀乐终于停了一会儿，所有的劳累在此刻得到一丝消解。父亲吃过了饭又去堂前一直跪着，磕着头，和奶奶总是有说不完的话，又或许有听不完的教导之言。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>footprints in memory of blog bugs</title>
    <link href="/2020/02/28/footprints-in-memory-of-blog-bugs/"/>
    <url>/2020/02/28/footprints-in-memory-of-blog-bugs/</url>
    
    <content type="html"><![CDATA[<h1 id="纪念这个来之不易的小白博客"><a href="#纪念这个来之不易的小白博客" class="headerlink" title="纪念这个来之不易的小白博客"></a>纪念这个来之不易的小白博客</h1><blockquote><p>虽然我也不知道会不会继续写下去，有个开头倒也是好的：）</p></blockquote><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p>自然是主题的自带配置文件了<br>设置十分友好，体现了源代码作者的大气和niubility<br>唯一要小本记下来的是外带文件的路径应该是以generate的文件夹为根目录,不是主题的文件夹。如</p><p><code>public/assets/alipay.jpg</code></p><p>开头不要加/划线！！！不要加<br>可以根据这个放到source的写作文件夹里</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>winter_vacation</title>
    <link href="/2020/02/18/winter-vacation/"/>
    <url>/2020/02/18/winter-vacation/</url>
    
    <content type="html"><![CDATA[<h1 id="pzw不堪回首的寒假"><a href="#pzw不堪回首的寒假" class="headerlink" title="pzw不堪回首的寒假"></a>pzw不堪回首的寒假</h1><h2 id="宏伟的计划本来是这样子的"><a href="#宏伟的计划本来是这样子的" class="headerlink" title="宏伟的计划本来是这样子的"></a>宏伟的计划本来是这样子的</h2><ul><li>Phthon + Django 虽然和后端关系大一点</li><li>git cmd 虽然感觉用得不多</li><li>sql 顺便学学大三狗的必修课</li><li>计（扯）划（不）太（下）多（去）了，略去回忆~</li></ul><h2 id="残酷的现实目前是这样子的"><a href="#残酷的现实目前是这样子的" class="headerlink" title="残酷的现实目前是这样子的"></a>残酷的现实目前是这样子的</h2><ul><li><p>HTML、CSS蜻蜓点水，结果基础不牢，地动山摇</p></li><li><p>ASP. NET里兜兜转转，浪费不少时间，弃之弃之</p></li><li><p>JavaScript+ jquery，咨询友校大佬，虎头蛇尾</p></li><li><p>Node.js是组长分配调研的任务，看完了三流网站的教程，现在感觉没有学到精髓  </p></li></ul><p>这里简单当个笔记本~~  </p><blockquote><p><code>JavaScript</code>是网页里实现动态交互的编程语言</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-built_in">document</span>.getElementByClassName( ).innerHTML=<span class="hljs-built_in">Date</span>();<br><span class="hljs-built_in">window</span>.history.go(<span class="hljs-number">-1</span>);<br></code></pre></td></tr></table></figure><p><code>jquery</code>是封装好了的script库，例如<code>$(&quot;p#demo&quot;).css(&quot;background-color&quot;,&quot;red&quot;);</code>  </p></blockquote><br /><blockquote><p>node.js是用来在服务器运行的编程语言</p><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs delphi"> fs.readFile(<span class="hljs-string">&#x27;input.txt&#x27;</span>,<span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(err, data)</span><span class="hljs-comment">&#123;  </span></span><br><span class="hljs-function"><span class="hljs-comment"> if(err) return;&#125;</span>)</span><br><span class="hljs-function">&gt;<span class="hljs-title">events</span>.<span class="hljs-title">EventEmitter</span>.<span class="hljs-title">on</span><span class="hljs-params">(<span class="hljs-string">&#x27;connection&#x27;</span>,handler)</span>;</span><br>&gt;<span class="hljs-keyword">var</span> conn_handler=<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">connected</span><span class="hljs-params">()</span><span class="hljs-comment">&#123;</span></span><br><span class="hljs-function"><span class="hljs-comment">&gt;......&#125;</span></span><br><span class="hljs-function">&gt;<span class="hljs-title">events</span>.<span class="hljs-title">EventEmitter</span>.<span class="hljs-title">on</span><span class="hljs-params">(<span class="hljs-string">&#x27;received&#x27;</span>,rec_handler)</span>;</span><br>&gt;<span class="hljs-keyword">var</span> rec_handler=<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">received</span><span class="hljs-params">()</span><span class="hljs-comment">&#123;</span></span><br><span class="hljs-function"><span class="hljs-comment">&gt;......&#125;</span></span><br></code></pre></td></tr></table></figure><p>大多数函数除了参数，后面备一个异步函数，先执行之后的代码同时调用此函数  </p></blockquote><br />  <blockquote><p>杂项 ：<br><code>Bootstrap</code>是io工具箱toolkit，起初用<code>jquery</code>写成<br><code>Angular</code>、<code>Vue</code>、<code>React</code>是正经框架framework，搭建结构<br><code>json</code> 是 JavaScript Object Notation</p><blockquote><p>做个笔记————package-lock.json&amp; package.json<br>锁定包的版本，手动更改package.json文件安装将不会更新包，想要更新只能使用 <code>npm install xxx@1.0.0 --save </code>这种方式来进行版本更新package-lock.json 文件才可。<br>另外，package-lock.json 文件中已经记录了整个 node_modules 文件夹的树状结构，加快了npm install 的速度。<br><code>json</code>使得ajax得以实现（这个没见过实例）<br>ajax典型对象是<code>XMLHttpRequest</code>，用来在js中与服务器异步交换数据  </p></blockquote></blockquote><h2 id="关于这个blog"><a href="#关于这个blog" class="headerlink" title="关于这个blog"></a>关于这个blog</h2><p>探索npm&amp;node.js的时候了解了hexo，搭建过程都是照葫芦画瓢，问起来原理什么的，也不见得答得上来。真正头大的是主题的改造，真是 “生命不息，折（zuo)腾（si）不止”。尤其是拖延症拖到了月底，才发现想要修改它简直是从零开始。于是粗制滥造改造工程，在几天之内成为了豆腐渣，中途有小bug差点害我要重新搭一个。背景图，大小，选择器名字，配色，看得两眼发光(晕)好像对整个构造多明白了一些，自己写一个就免了免了。码程序的事，能叫偷码？尚未解决的，有  </p><ol><li>小插件和特效，说白了还是js不会自己编呐</li><li>相册，大神都给的python程序，触及没来得及开发的操作盲区</li><li>标签归档，隐藏什么的功能，假博客也暂时用不上orz</li><li>为了凑数，毅然决然决定，再写一个diary给这个破网站留个纪念</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/02/08/hello-world/"/>
    <url>/2020/02/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
